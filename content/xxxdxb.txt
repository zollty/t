<p>题干=<br/></p><p>ElasticSearch集群的节点有哪些类型（node.role）？</p><p>答案=</p><p>参见：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html</a></p><p>简要说明：</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>候选主节点：Master eligible node (m);&nbsp;（从中会选出一个主节点）</p></li><li><p>数据节点：Data node (d);&nbsp;</p></li><li><p>转换(过滤)节点：Ingest node (i); 【Ingest nodes are able to apply an ingest pipeline to a document in order to transform and enrich the document before indexing】</p></li><li><p>协调节点（客户端节点）：Coordinating node only (-).【接收客户端请求，协调各个节点去处理，然后汇总处理结果返回给客户端】</p></li><li><p>（部落节点：Tribe node）【it is a <span style="text-decoration: underline;">special type of coordinating</span> only node that can connect to <span style="text-decoration: underline;">multiple clusters</span> and perform search and other operations across all connected clusters.】<br/></p></li></ul><p>参考资料：</p><p>[Elasticsearch节点类型]:&nbsp;<a href="https://www.2cto.com/kf/201708/664785.html">https://www.2cto.com/kf/201708/664785.html</a></p><p>[谈一谈Elasticsearch的集群部署]: <a href="https://blog.csdn.net/zwgdft/article/details/54585644">https://blog.csdn.net/zwgdft/article/details/54585644</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html</a></p><p><br/></p><p>补充：</p><p>查看集群的node信息命令：GET /_cat/nodes?v</p><p>结果如下：</p><p>ip&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;heap.percent&nbsp; ram.percent&nbsp; cpu&nbsp; &nbsp;load_1m&nbsp; &nbsp; &nbsp; node.role&nbsp; &nbsp; master&nbsp; &nbsp; name</p><p>127.0.0.1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;65&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 99&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;42&nbsp; &nbsp; &nbsp; 3.07&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mdi&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*(yes)&nbsp; &nbsp; mJw06l1</p><p>mdi代表：master &amp; data &amp; ingest<br/></p><p>参考文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-nodes.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-nodes.html</a></p><p><br/></p><p>题干=</p><p>Elasticsearch是如何避免脑裂现象的？</p><p>比如，ElasticSearch共20个节点，其中的10个选了一个master，另外10个选了另一个master，怎么避免这种情况？</p><p>答案=</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="white-space: normal;">当集群中 master候选节点(node.master: true) 的个数 N&gt;=3 时，通过设置<span style="font-weight: 700;">最小master候选节点数量</span>大于总数的一半来避免脑裂：discovery.zen.<span style="font-weight: 700;">minimum_master_nodes</span>: (N/2)+1</p></li><li><p style="white-space: normal;">注意N不能等于2，如果有两个节点，则只能一个为master候选节点（node.master: true），把另外一个node.master改成false，不参与master候选。</p></li></ul><p><br/></p><p>题干=</p><p>Elasticsearch是如何实现Master选举的？</p><p>答案=</p><p>Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（<span style="text-decoration: underline;">单播模块包含一个主机列表以控制哪些节点需要ping通</span>）这两部分；</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</p></li><li><p>如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</p></li></ul><p>补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</p><p><br/></p><p>题干=</p><p>客户端在和集群连接时，如何选择特定的节点执行请求的？</p><p>答案=</p><p>TransportClient利用transport模块远程连接一个elasticsearch集群。它并不加入到集群中，只是简单的获得一个或者多个初始化的transport地址，并以 轮询 的方式与这些地址进行通信。</p><p><br/></p><p>题干=</p><p>Elasticsearch的部署，有哪些优化方法？</p><p>答案=</p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p>优化操作系统参数和ES参数（参见<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/bootstrap-checks.html" target="_blank">bootstrap-checks</a>）；</p></li><li><p>增加内存，物理内存的50%将用于Lucene，16G的内存对ES来说太小；</p></li><li><p>禁用操作系统swapping；</p></li><li><p>分离Master Node和Data Node，并考虑分离Ingest Node；</p></li><li><p>合理分配索引分片（参见<a href="https://segmentfault.com/a/1190000008868585" target="_blank">减少索引分片</a>）;<br/></p></li><li><p>* 增加data-node节点;</p></li><li><p>* 冷热数据分离；</p></li><li><p>* 使用SSD；</p></li></ol><p><br/></p><p>具体如下：</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>64 GB 内存的机器是非常理想的， 但是32 GB 和16 GB 机器也是很常见的。少于8 GB 会适得其反。</p></li><li><p>把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过ES_HEAP_SIZE 环境变量设置。</p></li><li><p>内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。参见：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html" target="_blank">disable swapping</a><br/></p></li><li><p>不要随意修改垃圾回收器（CMS）和各个线程池的大小。</p></li><li><p>Lucene 使用了大量的文件。同时，Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。参见：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/file-descriptors.html" target="_blank">enlarge ulimit</a></p></li><li><p>如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</p></li><li><p>如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起，SSD 是一个好的选择。</p></li><li><p>即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。</p></li><li><p>请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 Elasticsearch 的几个地方，使用 Java 的本地序列化。</p></li><li><p>通过设置gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。</p></li><li><p>Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。</p></li></ul><p><br/></p><p>补充1：</p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p><a href="https://elasticsearch.cn/article/110" target="_blank">大规模Elasticsearch集群优化心得</a></p></li><li><p><a href="https://blog.csdn.net/wuxiao5570/article/details/56677484" target="_blank">Elasticsearch 存储方式和管理优化细节</a></p></li></ol><p><br/></p><p>补充2：索引阶段性能提升方法</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。</p></li><li><p>存储：使用 SSD</p></li><li><p>段和合并：Elasticsearch 默认值是 20 MB/s，对机械磁盘应该是个不错的设置。如果你用的是 SSD，可以考虑提高到 100–200 MB/s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的 512 MB 到更大一些的值，比如 1 GB，这可以在一次清空触发的时候在事务日志里积累出更大的段。</p></li><li><p>如果你的搜索结果不需要近实时的准确度，考虑把每个索引的index.refresh_interval 改到30s。</p></li><li><p>如果你在做大批量导入，考虑通过设置index.number_of_replicas: 0 关闭副本。</p></li></ul><p><br/></p><p>题干=</p><p>谈一下你对ES中的几个概念的理解：索引(index)、分片（shards）、river、gateway。</p><p>答案=</p><p><strong>数据源（River）</strong></p><p>代表es的一个<strong>数据源</strong>，也是其它存储方式（如：数据库）同步数据到es的一个方法。它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的，river这个功能将会在后面的文件中重点说到。</p><p><strong>网关（gateway）</strong></p><p>代表es索引的<strong>持久化存储</strong>方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再重新启动时就会从gateway中读取索引数据。<span style="text-decoration: underline;">es支持多种类型的gateway</span>，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。</p><p><br/></p><p><strong>索引（index）</strong></p><p>ElasticSearch将它的<span style="text-decoration: underline;">数据存储</span>在一个或多个索引（index）中。用SQL领域的术语来类比，<strong>索引就像数据库</strong>，一个索引就是一个库，可以向索引写入文档或者从索引中读取文档，并通过ElasticSearch内部使用Lucene将数据写入索引或从索引中检索数据。</p><p><strong>分片和复制（shards and replicas）</strong></p><p>&nbsp; &nbsp; 一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点可能没有这样大的磁盘空间来存储或者单个节点处理搜索请求，响应会太慢。</p><p><br/></p><p>为了解决这个问题，Elasticsearch提供了<span style="text-decoration: underline;">将索引划分成多片的能力</span>，这些片叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引” 可以被放置到集群中的任何节点上。</p><p><br/></p><p>分片之所以重要，主要有两方面的原因：</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>允许你水平分割/扩展你的内容容量</p></li><li><p>允许你在分片（位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量&nbsp;</p></li></ul><p>至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的。</p><p><br/></p><p>在一个网络/云的环境里，失败随时都可能发生。在某个分片/节点因为某些原因处于离线状态或者消失的情况下，故障转移机制是非常有用且强烈推荐的。为此， Elasticsearch允许你<span style="text-decoration: underline;">创建分片的一份或多份拷贝，这些拷贝叫做复制分片</span>，或者直接叫复制。</p><p><br/></p><p>在分片/节点失败的情况下，复制提供了高可用性。复制分片不与原/主要分片置于同一节点上是非常重要的。因为搜索可以在所有的复制上并行运行，复制可以扩展你的搜索量/吞吐量。<br/></p><p>总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（即没有复制） 或多次。<span style="text-decoration: underline;">一旦复制了，每个索引就有了主分片（作为复制源的分片）和复制分片（主分片的拷贝）</span>。</p><p><br/></p><p>分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你不能再改变分片的数量。</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>5.X默认每个索引5个主分片，每个主分片有1个复制分片。</p></li></ul><p>这意味着，默认情况下，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样每个索引总共就有10个分片。</p><p><br/></p><p>参考资料：</p><p><a href="https://www.cnblogs.com/xiaochina/p/6855591.html">https://www.cnblogs.com/xiaochina/p/6855591.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/_basic_concepts.html">https://www.elastic.co/guide/en/elasticsearch/reference/6.1/_basic_concepts.html</a></p><p>[关于索引的分片和复制]:&nbsp;<a href="https://blog.csdn.net/zwgdft/article/details/54585644#分片与集群状态" target="_self">https://blog.csdn.net/zwgdft/article/details/54585644</a></p><p><br/></p><p>题干=</p><p><span style="text-decoration: underline;">一个索引下多个type可能会导致什么样的问题？</span></p><p>OR</p><p><span style="text-decoration: underline;">为什么ElasticSearch 6.0废弃了之前版本中的Type的概念，官方推荐的做法是什么？</span></p><p><br/></p><p>答案=</p><p>6.0版本，官方对Type的解释是：<br/></p><p>A type used to be a <strong>logical</strong> category/<strong>partition</strong> of your index to allow you to <strong>store</strong> different types of documents in the same index, eg one type for users, another type for blog posts. It is no longer possible to create multiple types in an index, and <strong>the whole concept of types will be removed in a later version.</strong> See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/removal-of-types.html" target="_self">Removal of mapping types</a> for more.</p><p>废弃的原因：多个Type是逻辑隔离，而Lucene在处理同一个Index的数据时，会一视同仁，导致个多Type中的数据格式必须一致（比如Type1中有个deleted字段是data类型，而在Type2中也有个deleted字段是boolean类型，就会冲突、出错），另外，如果一个Index中有多个数据结构差异很大的Type，那么Lucene的压缩效率会很低。</p><p>所以，推荐的做法就是，一个Index只存储一种Type的数据，<span style="text-decoration: underline;">不同的Type使用不同的Index</span>。</p><p>另外，you may not want to waste an entire shard for a collection of only a few thousand documents. In this case, you can implement your own custom type field which will work in a similar way to the old _type.</p><p>也就是说，以前的Type也可以变相的实现：</p><p>合并所有的Type到一个Document结构中，数据中增加一个 type字段用于区分。例如</p><pre class="brush:js;toolbar:false">&quot;user&quot;:&nbsp;{
&nbsp;&nbsp;&quot;properties&quot;:&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&quot;name&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;text&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;user_name&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;keyword&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;email&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;keyword&quot;&nbsp;}
&nbsp;&nbsp;}
},
&quot;tweet&quot;:&nbsp;{
&nbsp;&nbsp;&quot;properties&quot;:&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&quot;content&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;text&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;user_name&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;keyword&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;tweeted_at&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;date&quot;&nbsp;}
&nbsp;&nbsp;}
}
==&gt;&nbsp;合并成一个：
&quot;doc&quot;:&nbsp;{
&nbsp;&nbsp;&quot;properties&quot;:&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&quot;type&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;keyword&quot;&nbsp;},&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&quot;name&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;text&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;user_name&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;keyword&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;email&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;keyword&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;content&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;text&quot;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;&quot;tweeted_at&quot;:&nbsp;{&nbsp;&quot;type&quot;:&nbsp;&quot;date&quot;&nbsp;}
&nbsp;&nbsp;}
}
查询的时候，根据type来filter即可：
&quot;filter&quot;:&nbsp;{
&nbsp;&nbsp;&quot;match&quot;:&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&quot;type&quot;:&nbsp;&quot;tweet&quot;&nbsp;
&nbsp;&nbsp;}
}</pre><p><br/></p><p>题干=</p><p>ElasticSearch内存使用原理和优化</p><p>答案=</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。</p></li><li><p>各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。</p></li><li><p>避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan &amp; scroll api来实现。</p></li><li><p>cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。</p></li><li><p>想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。</p></li><li><p>根据监控数据理解内存需求，合理配置各类circuit breaker，将内存溢出风险降低到最低。</p></li></ul><p>参考：<a href="https://elasticsearch.cn/article/32">https://elasticsearch.cn/article/32</a></p><p><br/></p><p>题干=<br/></p><p>ElasticSearch集群的健康状态有哪几种？</p><p>答案=</p><p>通过API（http://localhost:9200/_cluster/health?pretty）可以查看集群的状态，</p><p>通常集群的状态分为三种：</p><ul class=" list-paddingleft-2"><li><p><span style="color: rgb(192, 0, 0);">Red</span>，表示有主<span style="text-decoration: underline;">分片没有分配</span>，某些数据不可用。</p></li><li><p>Yellow，表示主分片都已分配，数据都可用，但是有<span style="text-decoration: underline;">复制分片</span>没有分配。</p></li><li><p><span style="color: rgb(0, 176, 80);">Green</span>，表示主分片和复制分片都已分配，一切正常。</p></li></ul><p><br/></p><p>题干=</p><p>Elasticsearch的缺点有哪些？你觉得可以在哪些地方进行改进？</p><p>答案=</p><p>1、主要是性能和资源占用问题<br/></p><p>ES非常耗资源，特别是内存，官方推荐是64G，实际使用来看，按照标准用法，16G不太够，物理内存还得留一半给Lucene做索引。</p><p>另外，支持的客户端连接有限，在默认5个分片的情况下，3个20G内存的节点，支撑40个logstash日志客户端直连，CPU使用率直接300%，后面改成3个分片0个副本，才把CPU降到100%以内。</p><p>2、改进方案</p><p>业界流行的做法：客户端不直连 es，采用Kafka MQ作为日志中心缓存，能极大提高性能。另外，日志进ES之前，可以先基于流计算做过滤处理。</p><p><br/></p>